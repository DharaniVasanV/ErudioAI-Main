import os
import re
import uuid
from typing import List, Optional
from fastapi import APIRouter, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session
from google import genai

from .auth.jwt_utils import get_current_user
from .database.connection import get_db
from .models.chat import Conversation, ChatMessageDB

# Gemini client
api_key = os.getenv("GEMINI_API_KEY")
client = genai.Client(api_key=api_key) if api_key else None

router = APIRouter(prefix="/chat", tags=["chat"])

SYSTEM_PROMPT = """
You are ErudioAI, a friendly study assistant for school and college students.

- Explain topics briefly and clearly.
- Use simple language and bullet points.
- Stay focused on the topic the student asked about.
- After your explanation, add a final line in this exact format:
TOPIC_NAME: <short topic name>
"""

class ChatMessage(BaseModel):
    role: str  # "user" or "assistant"
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatMessage]
    conversation_id: Optional[str] = None  # null/new = create new conv

class ChatResponse(BaseModel):
    reply_text: str
    suggested_topic: Optional[str] = None
    conversation_id: str

class AddToPlanRequest(BaseModel):
    topic_name: str
    conversation_id: Optional[str] = None

class AddToPlanResponse(BaseModel):
    message: str
    suggested_day: str
    suggested_time: str

class ConversationSchema(BaseModel):
    id: str
    title: str
    created_at: str

class MessageSchema(BaseModel):
    id: str
    role: str
    text: str
    created_at: str

class QuizQuestionSchema(BaseModel):
    question: str
    options: List[str]
    correct: int

class QuizResponseSchema(BaseModel):
    topic: str
    questions: List[QuizQuestionSchema]

class TopicContentSchema(BaseModel):
    topic: str
    introduction: str
    key_concepts: List[str]
    formulas: List[str]
    example_problem: dict # {"question": str, "solution": str}

class GenerateRequest(BaseModel):
    topic_name: str



@router.post("", response_model=ChatResponse)
async def chat(
    req: ChatRequest,
    user=Depends(get_current_user),
    db: Session = Depends(get_db),
):
    # 1) Find or create conversation
    conv = None
    if req.conversation_id:
        # Check if it's a valid UUID format (frontend might send temp 'chat-' IDs)
        is_valid_uuid = True
        try:
            uuid.UUID(str(req.conversation_id))
        except ValueError:
            is_valid_uuid = False

        if is_valid_uuid:
            conv = (
                db.query(Conversation)
                .filter_by(id=req.conversation_id, user_id=user.id)
                .first()
            )

    if not conv:
        first_user_msg = next(
            (m.content for m in req.messages if m.role == "user"),
            "New chat",
        )
        conv = Conversation(user_id=user.id, title=first_user_msg[:40] + "...")
        db.add(conv)
        db.commit()
        db.refresh(conv)

    # 2) Save new user messages (last one)
    last_user = req.messages[-1]
    if last_user.role == "user":
        db_msg = ChatMessageDB(
            conversation_id=conv.id,
            role="user",
            text=last_user.content,
        )
        db.add(db_msg)
        db.commit()

    # 3) Generate Response
    full_text = None
    
    if not client:
        raise ValueError("GEMINI_API_KEY not configured")

    # Format history for Gemini
    contents = []
    for m in req.messages:
        role = "user" if m.role == "user" else "model"
        contents.append({
            "role": role,
            "parts": [{"text": m.content}]
        })

    # Try different Gemini model names
    models_to_try = [
        "gemini-2.0-flash",
        "gemini-3.1-pro",
        "gemini-2.5-flash",
        "gemini-1.5-flash",
        "gemini-1.5-flash-8b",
        "gemini-1.5-pro",
        "gemini-2.0-flash-exp",
        "gemini-3-flash-preview"
    ]
    
    last_error = None

    for model_name in models_to_try:
        try:
            print(f"Trying Gemini model: {model_name}")
            resp = client.models.generate_content(
                model=model_name,
                contents=contents,
                config={
                    "system_instruction": SYSTEM_PROMPT
                }
            )
            full_text = resp.text
            if full_text:
                print(f"âœ… Success: Response generated by {model_name}")
                break
        except Exception as e:
            last_error = e
            continue

    if not full_text:
        raise Exception(f"All Gemini models failed. Last error: {str(last_error)}")

    # 4) Extract TOPIC_NAME
    match = re.search(r"TOPIC_NAME:\s*(.+)", full_text)
    suggested_topic = match.group(1).strip() if match else None
    clean_text = re.sub(r"TOPIC_NAME:.*", "", full_text, flags=re.DOTALL).strip()

    # 5) Save assistant message
    db_msg = ChatMessageDB(
        conversation_id=conv.id,
        role="assistant",
        text=clean_text,
    )
    db.add(db_msg)
    db.commit()

    return ChatResponse(
        reply_text=clean_text,
        suggested_topic=suggested_topic,
        conversation_id=str(conv.id),
    )

@router.post("/add-to-plan", response_model=AddToPlanResponse)
async def add_to_plan(
    body: AddToPlanRequest,
    user=Depends(get_current_user),
    db: Session = Depends(get_db),
):
    # For now, suggest tomorrow at current time or next available slot
    from datetime import datetime, timedelta
    tomorrow = datetime.now() + timedelta(days=1)
    day_name = tomorrow.strftime("%A")
    time_slot = "18:00" # Default study time
    
    print(f"User {user.id} requested to add topic:", body.topic_name)
    return AddToPlanResponse(
        message=f"Added '{body.topic_name}' to your plan for {day_name}",
        suggested_day=day_name,
        suggested_time=time_slot
    )

@router.get("/history", response_model=List[ConversationSchema])
async def get_chat_history(
    user=Depends(get_current_user),
    db: Session = Depends(get_db),
):
    convs = (
        db.query(Conversation)
        .filter_by(user_id=user.id)
        .order_by(Conversation.created_at.desc())
        .limit(10)
        .all()
    )
    return [
        ConversationSchema(
            id=str(c.id),
            title=c.title,
            created_at=c.created_at.isoformat()
        )
        for c in convs
    ]

@router.get("/{conv_id}/messages", response_model=List[MessageSchema])
async def get_conversation_messages(
    conv_id: str,
    user=Depends(get_current_user),
    db: Session = Depends(get_db),
):
    try:
        uuid.UUID(str(conv_id))
    except ValueError:
        return [] # Return empty list for invalid temp IDs

    conv = (
        db.query(Conversation)
        .filter_by(id=conv_id, user_id=user.id)
        .first()
    )
    if not conv:
        from fastapi import HTTPException
        raise HTTPException(status_code=404, detail="Conversation not found")
    msgs = (
        db.query(ChatMessageDB)
        .filter_by(conversation_id=conv_id)
        .order_by(ChatMessageDB.created_at.asc())
        .all()
    )
    return [
        MessageSchema(
            id=str(m.id),
            role=m.role,
            text=m.text,
            created_at=m.created_at.isoformat()
        )
        for m in msgs
    ]

@router.delete("/{conv_id}")
async def delete_conversation(
    conv_id: str,
    user=Depends(get_current_user),
    db: Session = Depends(get_db),
):
    conv = db.query(Conversation).filter_by(id=conv_id, user_id=user.id).first()
    if not conv:
        from fastapi import HTTPException
        raise HTTPException(status_code=404, detail="Conversation not found")
    db.query(ChatMessageDB).filter_by(conversation_id=conv_id).delete()
    db.delete(conv)
    db.commit()
    return {"message": "Conversation deleted"}

@router.post("/generate-quiz", response_model=QuizResponseSchema)
async def generate_quiz(
    req: GenerateRequest,
    user=Depends(get_current_user),
):
    if not client:
        raise ValueError("GEMINI_API_KEY not configured")

    prompt = f"""
    Create a 5-question multiple choice quiz about the topic: {req.topic_name}
    Return the response as a valid JSON object with this structure:
    {{
        "topic": "{req.topic_name}",
        "questions": [
            {{
                "question": "question text",
                "options": ["opt1", "opt2", "opt3", "opt4"],
                "correct": 0
            }}
        ]
    }}
    Ensure exactly 5 questions.
    """
    
    # Use flash for speed
    resp = client.models.generate_content(
        model="gemini-1.5-flash",
        contents=prompt,
        config={
            "response_mime_type": "application/json"
        }
    )
    
    import json
    return json.loads(resp.text)

@router.post("/generate-topic-content", response_model=TopicContentSchema)
async def generate_topic_content(
    req: GenerateRequest,
    user=Depends(get_current_user),
):
    if not client:
        raise ValueError("GEMINI_API_KEY not configured")

    prompt = f"""
    Generate study content for the topic: {req.topic_name}
    Return the response as a valid JSON object with this structure:
    {{
        "topic": "{req.topic_name}",
        "introduction": "Brief overview of the topic...",
        "key_concepts": ["concept 1", "concept 2", ...],
        "formulas": ["formula 1", "formula 2", ...],
        "example_problem": {{
            "question": "A sample problem...",
            "solution": "Step-by-step solution..."
        }}
    }}
    Important: Keep it educational and concise for students.
    """
    
    resp = client.models.generate_content(
        model="gemini-1.5-flash",
        contents=prompt,
        config={
            "response_mime_type": "application/json"
        }
    )
    
    import json
    return json.loads(resp.text)

